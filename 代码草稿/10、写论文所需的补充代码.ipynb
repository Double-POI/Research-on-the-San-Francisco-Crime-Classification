{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "朴素贝叶斯的训练log损失为 2.582578\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "train_features_raw = np.load('./data/train_features.npy')\n",
    "train_labels_raw = np.load('./data/train_labels.npy')\n",
    "\n",
    "index = [i for i in range(len(train_features_raw))]\n",
    "np.random.shuffle(index)\n",
    "train_features = train_features_raw[index]\n",
    "train_labels = train_labels_raw[index]\n",
    "\n",
    "model = BernoulliNB(alpha=1.0)\n",
    "model.fit(train_features, train_labels)\n",
    "predicted = np.array(model.predict_proba(train_features))\n",
    "print(\"朴素贝叶斯的训练log损失为 %f\" % (log_loss(train_labels, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
      "[-2.58388939 -2.58387524 -2.58386181 -2.58384895 -2.58383655 -2.58382453]\n",
      "[0.00151963 0.00152036 0.00152083 0.00152111 0.00152125 0.00152128]\n",
      "{'alpha': 1.0}\n",
      "-2.5838245319029713\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_features_raw = np.load('./data/train_features.npy')\n",
    "train_labels_raw = np.load('./data/train_labels.npy')\n",
    "\n",
    "index = [i for i in range(len(train_features_raw))]\n",
    "np.random.shuffle(index)\n",
    "train_features = train_features_raw[index]\n",
    "train_labels = train_labels_raw[index]\n",
    "\n",
    "parameters = {\n",
    "    'alpha': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "}\n",
    "model = BernoulliNB(alpha=1.0)\n",
    "gsearch = GridSearchCV(model,\n",
    "                       param_grid=parameters,\n",
    "                       scoring='neg_log_loss',\n",
    "                       cv=3)\n",
    "gsearch.fit(train_features, train_labels)\n",
    "print(parameters)\n",
    "print(gsearch.cv_results_['mean_test_score'])\n",
    "print(gsearch.cv_results_['std_test_score'])\n",
    "print(gsearch.best_params_)\n",
    "print(gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha | mean_test_score | std_test_score\n",
    ":-: | :-: | :-:\n",
    "0.5 | 2.58388939 | 0.00151963\n",
    "0.6 | 2.58387524 | 0.00152036\n",
    "0.7 | 2.58386181 | 0.00152083\n",
    "0.8 | 2.58384895 | 0.00152111\n",
    "0.9 | 2.58383655 | 0.00152125\n",
    "1.0 | 2.58382453 | 0.00152128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "朴素贝叶斯的训练log损失为 2.582578\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_features_raw = np.load('./data/train_features.npy')\n",
    "train_labels_raw = np.load('./data/train_labels.npy')\n",
    "test_features = np.load('./data/test_features.npy')\n",
    "\n",
    "index = [i for i in range(len(train_features_raw))]\n",
    "np.random.shuffle(index)\n",
    "train_features = train_features_raw[index]\n",
    "train_labels = train_labels_raw[index]\n",
    "\n",
    "model = BernoulliNB(alpha=1.0)\n",
    "model.fit(train_features, train_labels)\n",
    "predicted = np.array(model.predict_proba(train_features))\n",
    "print(\"朴素贝叶斯的训练log损失为 %f\" % (log_loss(train_labels, predicted)))\n",
    "testResult = np.array(model.predict_proba(test_features))\n",
    "sampleSubmission = pd.read_csv('../input/sf-crime/sampleSubmission.csv.zip')\n",
    "Result_pd = pd.DataFrame(testResult,\n",
    "                         index=sampleSubmission.index,\n",
    "                         columns=sampleSubmission.columns[1:])\n",
    "Result_pd.to_csv('../working/sampleSubmission(bayes).csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林的训练log损失为 2.544871\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_features_raw = np.load('./data/train_features.npy')\n",
    "train_labels_raw = np.load('./data/train_labels.npy')\n",
    "\n",
    "index = [i for i in range(len(train_features_raw))]\n",
    "np.random.shuffle(index)\n",
    "train_features = train_features_raw[index]\n",
    "train_labels = train_labels_raw[index]\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=5)\n",
    "model.fit(train_features, train_labels)\n",
    "predicted = np.array(model.predict_proba(train_features))\n",
    "print(\"随机森林的训练log损失为 %f\" % (log_loss(train_labels, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [10, 30, 50, 70, 90]}\n",
      "[-2.45267495 -5.63315795 -6.73742927 -6.74492684 -6.74814227]\n",
      "[0.00077951 0.02050809 0.01977714 0.0103057  0.00515421]\n",
      "{'max_depth': 10}\n",
      "-2.45267495266959\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_features_raw = np.load('./data/train_features.npy')\n",
    "train_labels_raw = np.load('./data/train_labels.npy')\n",
    "\n",
    "index = [i for i in range(len(train_features_raw))]\n",
    "np.random.shuffle(index)\n",
    "train_features = train_features_raw[index]\n",
    "train_labels = train_labels_raw[index]\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [10, 30, 50, 70, 90],\n",
    "}\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=10)\n",
    "gsearch = GridSearchCV(model,\n",
    "                       param_grid=parameters,\n",
    "                       scoring='neg_log_loss',\n",
    "                       cv=3)\n",
    "gsearch.fit(train_features, train_labels)\n",
    "print(parameters)\n",
    "print(gsearch.cv_results_['mean_test_score'])\n",
    "print(gsearch.cv_results_['std_test_score'])\n",
    "print(gsearch.best_params_)\n",
    "print(gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [5, 6, 7, 8, 9, 10]}\n",
      "[-2.54637367 -2.52371166 -2.50549146 -2.48602735 -2.46992585 -2.45302022]\n",
      "[0.00167687 0.00274124 0.00204834 0.00095764 0.00031478 0.00141425]\n",
      "{'max_depth': 10}\n",
      "-2.4530202156447216\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_features_raw = np.load('./data/train_features.npy')\n",
    "train_labels_raw = np.load('./data/train_labels.npy')\n",
    "\n",
    "index = [i for i in range(len(train_features_raw))]\n",
    "np.random.shuffle(index)\n",
    "train_features = train_features_raw[index]\n",
    "train_labels = train_labels_raw[index]\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [5,6,7,8,9,10],\n",
    "}\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=10)\n",
    "gsearch = GridSearchCV(model,\n",
    "                       param_grid=parameters,\n",
    "                       scoring='neg_log_loss',\n",
    "                       cv=3)\n",
    "gsearch.fit(train_features, train_labels)\n",
    "print(parameters)\n",
    "print(gsearch.cv_results_['mean_test_score'])\n",
    "print(gsearch.cv_results_['std_test_score'])\n",
    "print(gsearch.best_params_)\n",
    "print(gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'min_samples_split': 50}, {'min_samples_split': 100}, {'min_samples_split': 150}]\n",
      "[-2.45253602 -2.45440453 -2.45478853]\n",
      "[0.00062034 0.00112358 0.0003685 ]\n",
      "{'min_samples_split': 50}\n",
      "-2.452536016669535\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_features_raw = np.load('./data/train_features.npy')\n",
    "train_labels_raw = np.load('./data/train_labels.npy')\n",
    "\n",
    "index = [i for i in range(len(train_features_raw))]\n",
    "np.random.shuffle(index)\n",
    "train_features = train_features_raw[index]\n",
    "train_labels = train_labels_raw[index]\n",
    "\n",
    "parameters = {\n",
    "    'min_samples_split': [50, 100, 150],\n",
    "}\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=10)\n",
    "gsearch = GridSearchCV(model,\n",
    "                       param_grid=parameters,\n",
    "                       scoring='neg_log_loss',\n",
    "                       cv=3)\n",
    "gsearch.fit(train_features, train_labels)\n",
    "print(gsearch.cv_results_['params'])\n",
    "print(gsearch.cv_results_['mean_test_score'])\n",
    "print(gsearch.cv_results_['std_test_score'])\n",
    "print(gsearch.best_params_)\n",
    "print(gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林的训练log损失为 2.426830\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_features_raw = np.load('./data/train_features.npy')\n",
    "train_labels_raw = np.load('./data/train_labels.npy')\n",
    "test_features = np.load('./data/test_features.npy')\n",
    "\n",
    "index = [i for i in range(len(train_features_raw))]\n",
    "np.random.shuffle(index)\n",
    "train_features = train_features_raw[index]\n",
    "train_labels = train_labels_raw[index]\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=50)\n",
    "model.fit(train_features, train_labels)\n",
    "predicted = np.array(model.predict_proba(train_features))\n",
    "print(\"随机森林的训练log损失为 %f\" % (log_loss(train_labels, predicted)))\n",
    "testResult = np.array(model.predict_proba(test_features))\n",
    "sampleSubmission = pd.read_csv('../input/sf-crime/sampleSubmission.csv.zip')\n",
    "Result_pd = pd.DataFrame(testResult,\n",
    "                         index=sampleSubmission.index,\n",
    "                         columns=sampleSubmission.columns[1:])\n",
    "Result_pd.to_csv('../working/sampleSubmission(RF).csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\XPS\\.conda\\envs\\Pytorch-learn\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 1.0\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([9.68570177, 9.99593321, 7.39587824, 7.55415122, 7.30878782,\n",
       "         6.99430537, 7.05458426, 7.15620748, 8.2196846 , 8.68378647,\n",
       "         7.23797774, 7.89089712, 0.44481166, 0.43116967, 0.45112761,\n",
       "         0.42054224]),\n",
       "  'std_fit_time': array([0.93817421, 1.19705085, 0.14596371, 0.37253698, 0.20882886,\n",
       "         0.05520022, 0.09928847, 0.22190341, 1.21468082, 0.60290298,\n",
       "         0.12958262, 0.21456815, 0.02993126, 0.00248536, 0.05310374,\n",
       "         0.02850384]),\n",
       "  'mean_score_time': array([7.6485467 , 7.59203132, 6.02355671, 5.8111047 , 6.1399134 ,\n",
       "         5.66716679, 5.90838122, 5.72467899, 6.57691749, 6.37295643,\n",
       "         5.83871833, 6.46122241, 0.        , 0.        , 0.        ,\n",
       "         0.        ]),\n",
       "  'std_score_time': array([0.96423401, 0.99631317, 0.16543788, 0.16955409, 0.39028413,\n",
       "         0.02258826, 0.38345302, 0.08372127, 0.7059352 , 0.47153759,\n",
       "         0.19372694, 0.64149406, 0.        , 0.        , 0.        ,\n",
       "         0.        ]),\n",
       "  'param_min_samples_leaf': masked_array(data=[0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.4,\n",
       "                     0.4, 1.0, 1.0, 1.0, 1.0],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_samples_split': masked_array(data=[0.7, 0.8, 0.9, 1.0, 0.7, 0.8, 0.9, 1.0, 0.7, 0.8, 0.9,\n",
       "                     1.0, 0.7, 0.8, 0.9, 1.0],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'min_samples_leaf': 0.2, 'min_samples_split': 0.7},\n",
       "   {'min_samples_leaf': 0.2, 'min_samples_split': 0.8},\n",
       "   {'min_samples_leaf': 0.2, 'min_samples_split': 0.9},\n",
       "   {'min_samples_leaf': 0.2, 'min_samples_split': 1.0},\n",
       "   {'min_samples_leaf': 0.3, 'min_samples_split': 0.7},\n",
       "   {'min_samples_leaf': 0.3, 'min_samples_split': 0.8},\n",
       "   {'min_samples_leaf': 0.3, 'min_samples_split': 0.9},\n",
       "   {'min_samples_leaf': 0.3, 'min_samples_split': 1.0},\n",
       "   {'min_samples_leaf': 0.4, 'min_samples_split': 0.7},\n",
       "   {'min_samples_leaf': 0.4, 'min_samples_split': 0.8},\n",
       "   {'min_samples_leaf': 0.4, 'min_samples_split': 0.9},\n",
       "   {'min_samples_leaf': 0.4, 'min_samples_split': 1.0},\n",
       "   {'min_samples_leaf': 1.0, 'min_samples_split': 0.7},\n",
       "   {'min_samples_leaf': 1.0, 'min_samples_split': 0.8},\n",
       "   {'min_samples_leaf': 1.0, 'min_samples_split': 0.9},\n",
       "   {'min_samples_leaf': 1.0, 'min_samples_split': 1.0}],\n",
       "  'split0_test_score': array([-2.68031106, -2.68031118, -2.6803109 , -2.68031082, -2.68031131,\n",
       "         -2.68031114, -2.68031106, -2.68031125, -2.68031096, -2.68031096,\n",
       "         -2.68031089, -2.68031088,         nan,         nan,         nan,\n",
       "                 nan]),\n",
       "  'split1_test_score': array([-2.6803313 , -2.68033115, -2.68033113, -2.68033158, -2.68033116,\n",
       "         -2.68033155, -2.68033101, -2.68033134, -2.68033146, -2.68033129,\n",
       "         -2.68033118, -2.68033125,         nan,         nan,         nan,\n",
       "                 nan]),\n",
       "  'split2_test_score': array([-2.68033445, -2.68033417, -2.68033404, -2.68033413, -2.68033415,\n",
       "         -2.68033405, -2.68033435, -2.68033403, -2.68033381, -2.6803343 ,\n",
       "         -2.68033398, -2.68033442,         nan,         nan,         nan,\n",
       "                 nan]),\n",
       "  'mean_test_score': array([-2.6803256 , -2.6803255 , -2.68032536, -2.68032551, -2.68032554,\n",
       "         -2.68032558, -2.68032547, -2.68032554, -2.68032541, -2.68032552,\n",
       "         -2.68032535, -2.68032552,         nan,         nan,         nan,\n",
       "                 nan]),\n",
       "  'std_test_score': array([1.03621248e-05, 1.01968897e-05, 1.02913316e-05, 1.04401382e-05,\n",
       "         1.01337429e-05, 1.02612442e-05, 1.02843344e-05, 1.01631730e-05,\n",
       "         1.02623264e-05, 1.03674412e-05, 1.02871059e-05, 1.04281635e-05,\n",
       "                    nan,            nan,            nan,            nan]),\n",
       "  'rank_test_score': array([12,  5,  2,  6,  9, 11,  4, 10,  3,  7,  1,  8, 13, 14, 15, 16])},\n",
       " {'min_samples_leaf': 0.4, 'min_samples_split': 0.9},\n",
       " -2.6803253484738345)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'min_samples_split': [0.7, 0.8, 0.9, 1.0],\n",
    "    'min_samples_leaf': [0.2, 0.3, 0.4, 0.5]\n",
    "}\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=2)\n",
    "gsearch = GridSearchCV(model,\n",
    "                       param_grid=parameters,\n",
    "                       scoring='neg_log_loss',\n",
    "                       cv=3)\n",
    "gsearch.fit(train_features, train_labels)\n",
    "gsearch.cv_results_, gsearch.best_params_, gsearch.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('Pytorch-learn': conda)",
   "language": "python",
   "name": "python361064bitpytorchlearnconda080df47efea24539a61202fa66a72562"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
