{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sf-crime/test.csv.zip\n",
      "/kaggle/input/sf-crime/sampleSubmission.csv.zip\n",
      "/kaggle/input/sf-crime/train.csv.zip\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import something I need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#作者：lwq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IS GPU available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/sf-crime/train.csv.zip', parse_dates=['Dates'])\n",
    "test_data = pd.read_csv('/kaggle/input/sf-crime/test.csv.zip', parse_dates=['Dates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 9 columns):\n",
      "Dates         878049 non-null datetime64[ns]\n",
      "Category      878049 non-null object\n",
      "Descript      878049 non-null object\n",
      "DayOfWeek     878049 non-null object\n",
      "PdDistrict    878049 non-null object\n",
      "Resolution    878049 non-null object\n",
      "Address       878049 non-null object\n",
      "X             878049 non-null float64\n",
      "Y             878049 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(2), object(6)\n",
      "memory usage: 60.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 884262 entries, 0 to 884261\n",
      "Data columns (total 7 columns):\n",
      "Id            884262 non-null int64\n",
      "Dates         884262 non-null datetime64[ns]\n",
      "DayOfWeek     884262 non-null object\n",
      "PdDistrict    884262 non-null object\n",
      "Address       884262 non-null object\n",
      "X             884262 non-null float64\n",
      "Y             884262 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(3)\n",
      "memory usage: 47.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat((train_data.iloc[:, [0, 3, 4, 6, 7, 8]],\n",
    "                          test_data.iloc[:, [1, 2, 3, 4, 5, 6]]),\n",
    "                         sort=False)\n",
    "\n",
    "num_train = train_data.shape[0]\n",
    "\n",
    "train_labels = pd.get_dummies(train_data['Category']).values\n",
    "num_outputs = train_labels.shape[1]\n",
    "\n",
    "all_features['year'] = all_features.Dates.dt.year\n",
    "all_features['month'] = all_features.Dates.dt.month\n",
    "all_features['new_year'] = all_features['month'].apply(\n",
    "    lambda x: 1 if x == 1 or x == 2 else 0)\n",
    "all_features['day'] = all_features.Dates.dt.day\n",
    "all_features['hour'] = all_features.Dates.dt.hour\n",
    "all_features['evening'] = all_features['hour'].apply(lambda x: 1\n",
    "                                                     if x >= 18 else 0)\n",
    "\n",
    "wkm = {\n",
    "    'Monday': 0,\n",
    "    'Tuesday': 1,\n",
    "    'Wednesday': 2,\n",
    "    'Thursday': 3,\n",
    "    'Friday': 4,\n",
    "    'Saturday': 5,\n",
    "    'Sunday': 6\n",
    "}\n",
    "all_features['DayOfWeek'] = all_features['DayOfWeek'].apply(lambda x: wkm[x])\n",
    "all_features['weekend'] = all_features['DayOfWeek'].apply(\n",
    "    lambda x: 1 if x == 4 or x == 5 else 0)\n",
    "\n",
    "OneHot_features = pd.get_dummies(all_features['PdDistrict'])\n",
    "\n",
    "all_features['block'] = all_features['Address'].apply(\n",
    "    lambda x: 1 if 'block' in x.lower() else 0)\n",
    "\n",
    "PCA_features = all_features[['X', 'Y']].values\n",
    "Standard_features = all_features[['DayOfWeek', 'year', 'month', 'day',\n",
    "                                  'hour']].values\n",
    "OneHot_features = pd.concat([\n",
    "    OneHot_features, all_features[['new_year', 'evening', 'weekend', 'block']]\n",
    "],\n",
    "                            axis=1).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Standard_features)\n",
    "Standard_features = scaler.transform(Standard_features)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(PCA_features)\n",
    "PCA_features = pca.transform(PCA_features)\n",
    "\n",
    "all_features = np.concatenate(\n",
    "    (PCA_features, Standard_features, OneHot_features), axis=1)\n",
    "\n",
    "train_features = all_features[:num_train]\n",
    "num_inputs = train_features.shape[1]\n",
    "test_features = all_features[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(Residual, self).__init__()\n",
    "        self.middle_L = nn.Linear(num_inputs, num_outputs)\n",
    "        self.middle_R = nn.ReLU(num_outputs)\n",
    "        if num_inputs != num_outputs:\n",
    "            self.right = nn.Linear(num_inputs, num_outputs)\n",
    "        else:\n",
    "            self.right = None\n",
    "        self.middle_B = nn.BatchNorm1d(num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.middle_B(self.middle_R(self.middle_L(X)))\n",
    "        if self.right:\n",
    "            X = self.right(X)\n",
    "        return Y + X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_model(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(build_model, self).__init__()\n",
    "        self.net = nn.Sequential()\n",
    "        self.net.add_module('Residual1', Residual(num_inputs, 1024))\n",
    "        self.net.add_module('Residual2', Residual(1024, 512))\n",
    "        self.net.add_module('Residual3', Residual(512, 512))\n",
    "        self.net.add_module('Residual4', Residual(512, 256))\n",
    "        self.net.add_module('Residual5', Residual(256, 256))\n",
    "        self.net.add_module('Residual6', Residual(256, 128))\n",
    "        self.net.add_module('Residual7', Residual(128, 128))\n",
    "        self.net.add_module('Residual8', Residual(128, 64))\n",
    "        self.net.add_module('Residual9', Residual(64, 64))\n",
    "        self.net.add_module('Linear-out', nn.Linear(64, num_outputs))\n",
    "        self.net.add_module('Softmax', nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "net = build_model(num_inputs, num_outputs).cuda(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassLogLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassLogLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return -(y_true *\n",
    "                 torch.log(y_pred.float() + 1.00000000e-15)) / y_true.shape[0]\n",
    "\n",
    "\n",
    "loss = MultiClassLogLoss().cuda(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_iter(train_features, train_labels, batch_size):\n",
    "    train_features = torch.tensor(train_features, dtype=torch.float).cuda(0)\n",
    "    train_labels = torch.tensor(train_labels).cuda(0)\n",
    "    dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "def show_loss(net, loss, features, labels, team):\n",
    "    net.eval()\n",
    "    batch = make_iter(features, labels, 1024)\n",
    "    loss_num = 0\n",
    "    n = 0\n",
    "    for x, y in batch:\n",
    "        loss_num += loss(net(x), y).sum().item()\n",
    "        n += 1\n",
    "    print(team, end=' ')\n",
    "    print('loss:', loss_num / n)\n",
    "\n",
    "\n",
    "def train(features, labels, batch_size):\n",
    "    net.train()\n",
    "    train_iter = make_iter(features, labels, batch_size)\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y).sum()\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    show_loss(net, loss, features, labels, '训练集')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up super parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_epochs = 10\n",
    "num_epochs = 75\n",
    "k_fold_num = 5\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "k_fold = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1轮：\n",
      "训练集 loss: 2.532128783372732\n",
      "第2轮：\n",
      "训练集 loss: 2.5117432226389993\n",
      "第3轮：\n",
      "训练集 loss: 2.4987093857674054\n",
      "第4轮：\n",
      "训练集 loss: 2.4650355627486755\n",
      "第5轮：\n",
      "训练集 loss: 2.44225353989012\n",
      "第6轮：\n",
      "训练集 loss: 2.432890730860072\n",
      "第7轮：\n",
      "训练集 loss: 2.4221955523902166\n",
      "第8轮：\n",
      "训练集 loss: 2.4226611791512904\n",
      "第9轮：\n",
      "训练集 loss: 2.4129180616432135\n",
      "第10轮：\n",
      "训练集 loss: 2.41405027535134\n",
      "第11轮：\n",
      "训练集 loss: 2.4008438345435614\n",
      "第12轮：\n",
      "训练集 loss: 2.40186852369553\n",
      "第13轮：\n",
      "训练集 loss: 2.396401159691088\n",
      "第14轮：\n",
      "训练集 loss: 2.392729426875259\n",
      "第15轮：\n",
      "训练集 loss: 2.3865575167960498\n",
      "第16轮：\n",
      "训练集 loss: 2.3903897981265763\n",
      "第17轮：\n",
      "训练集 loss: 2.391178473448142\n",
      "第18轮：\n",
      "训练集 loss: 2.390286771011797\n",
      "第19轮：\n",
      "训练集 loss: 2.38301262099704\n",
      "第20轮：\n",
      "训练集 loss: 2.3805301756291954\n",
      "第21轮：\n",
      "训练集 loss: 2.3761558679989725\n",
      "第22轮：\n",
      "训练集 loss: 2.3768800711020446\n",
      "第23轮：\n",
      "训练集 loss: 2.359234025428345\n",
      "第24轮：\n",
      "训练集 loss: 2.3556665871248934\n",
      "第25轮：\n",
      "训练集 loss: 2.3613409704261725\n",
      "第26轮：\n",
      "训练集 loss: 2.3609874215159383\n",
      "第27轮：\n",
      "训练集 loss: 2.341428651676311\n",
      "第28轮：\n",
      "训练集 loss: 2.342289823474306\n",
      "第29轮：\n",
      "训练集 loss: 2.3466516399716997\n",
      "第30轮：\n",
      "训练集 loss: 2.3290268788526665\n",
      "第31轮：\n",
      "训练集 loss: 2.344144325156312\n",
      "第32轮：\n",
      "训练集 loss: 2.3238662164528052\n",
      "第33轮：\n",
      "训练集 loss: 2.3338206492381772\n",
      "第34轮：\n",
      "训练集 loss: 2.316863007478781\n",
      "第35轮：\n",
      "训练集 loss: 2.3163462466015403\n",
      "第36轮：\n",
      "训练集 loss: 2.304803479801525\n",
      "第37轮：\n",
      "训练集 loss: 2.3276602871768124\n",
      "第38轮：\n",
      "训练集 loss: 2.3012462073550637\n",
      "第39轮：\n",
      "训练集 loss: 2.296868058629247\n",
      "第40轮：\n",
      "训练集 loss: 2.292901530132427\n",
      "第41轮：\n",
      "训练集 loss: 2.2828861566690297\n",
      "第42轮：\n",
      "训练集 loss: 2.299591307039861\n",
      "第43轮：\n",
      "训练集 loss: 2.2943672689246686\n",
      "第44轮：\n",
      "训练集 loss: 2.2703809335237337\n",
      "第45轮：\n",
      "训练集 loss: 2.288071677401349\n",
      "第46轮：\n",
      "训练集 loss: 2.261207561670761\n",
      "第47轮：\n",
      "训练集 loss: 2.2592816775217477\n",
      "第48轮：\n",
      "训练集 loss: 2.245214062415081\n",
      "第49轮：\n",
      "训练集 loss: 2.270078106360002\n",
      "第50轮：\n",
      "训练集 loss: 2.2344410322207113\n",
      "第51轮：\n",
      "训练集 loss: 2.2556811551669815\n",
      "第52轮：\n",
      "训练集 loss: 2.262334980608978\n",
      "第53轮：\n",
      "训练集 loss: 2.256335735876799\n",
      "第54轮：\n",
      "训练集 loss: 2.236338401452089\n",
      "第55轮：\n",
      "训练集 loss: 2.2431761026382446\n",
      "第56轮：\n",
      "训练集 loss: 2.2201628512713736\n",
      "第57轮：\n",
      "训练集 loss: 2.199509350292055\n",
      "第58轮：\n",
      "训练集 loss: 2.1961013437151076\n",
      "第59轮：\n",
      "训练集 loss: 2.1945995867669166\n",
      "第60轮：\n",
      "训练集 loss: 2.214539958880498\n",
      "第61轮：\n",
      "训练集 loss: 2.191579738141218\n",
      "第62轮：\n",
      "训练集 loss: 2.1802288388316726\n",
      "第63轮：\n",
      "训练集 loss: 2.2214432590769166\n",
      "第64轮：\n",
      "训练集 loss: 2.2117651773221567\n",
      "第65轮：\n",
      "训练集 loss: 2.164032549569101\n",
      "第66轮：\n",
      "训练集 loss: 2.1991856762301394\n",
      "第67轮：\n",
      "训练集 loss: 2.1562348823725204\n",
      "第68轮：\n",
      "训练集 loss: 2.18965525727172\n",
      "第69轮：\n",
      "训练集 loss: 2.1484812295242346\n",
      "第70轮：\n",
      "训练集 loss: 2.145705941951636\n",
      "第71轮：\n",
      "训练集 loss: 2.1530181847530088\n",
      "第72轮：\n",
      "训练集 loss: 2.154164569916981\n",
      "第73轮：\n",
      "训练集 loss: 2.159680441542939\n",
      "第74轮：\n",
      "训练集 loss: 2.1619253325295613\n",
      "第75轮：\n",
      "训练集 loss: 2.161952587552282\n"
     ]
    }
   ],
   "source": [
    "if k_fold:\n",
    "    kf = KFold(n_splits=k_fold_num, shuffle=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        fold_num = 0\n",
    "        for train_index, test_index in kf.split(train_features):\n",
    "            X_train, X_test = train_features[train_index], train_features[\n",
    "                test_index]\n",
    "            y_train, y_test = train_labels[train_index], train_labels[\n",
    "                test_index]\n",
    "            print('第%d轮的第%d折：' % (epoch + 1, fold_num + 1))\n",
    "            fold_num += 1\n",
    "            train(X_train, y_train, batch_size)\n",
    "            show_loss(net, loss, X_test, y_test, '测试集')\n",
    "else:\n",
    "    for epoch in range(num_epochs):\n",
    "        print('第%d轮：' % (epoch + 1))\n",
    "        train(train_features, train_labels, batch_size)\n",
    "\n",
    "    net.eval()\n",
    "    test_iter = torch.utils.data.DataLoader(torch.tensor(test_features,\n",
    "                                                         dtype=torch.float).cuda(0),\n",
    "                                            1024,\n",
    "                                            shuffle=False)\n",
    "    testResult = [line for x in test_iter for line in net(x).cpu().detach().numpy()]\n",
    "    sampleSubmission = pd.read_csv('/kaggle/input/sf-crime/sampleSubmission.csv.zip')\n",
    "    Result_pd = pd.DataFrame(testResult,\n",
    "                             index=sampleSubmission.index,\n",
    "                             columns=sampleSubmission.columns[1:])\n",
    "    Result_pd.to_csv('/kaggle/working/sampleSubmission(v0.5).csv', index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
